{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversial Networks \n",
    "\n",
    "    ###Code along practice/Implementation from Udemy Tensor-Flow Course - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grab data\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rhasan\\Downloads\\Tensorflow-Bootcamp\\Scikit IBM\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\rhasan\\Downloads\\Tensorflow-Bootcamp\\Scikit IBM\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting C:\\Users\\rhasan\\Downloads\\Tensorflow-Bootcamp\\Scikit IBM\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\rhasan\\Downloads\\Tensorflow-Bootcamp\\Scikit IBM\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "##extract data\n",
    "mnist = input_data.read_data_sets(\"C:\\\\Users\\\\rhasan\\\\Downloads\\\\Tensorflow-Bootcamp\\\\Scikit IBM\\\\MNIST_data\\\\\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xe2547f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUIQfCIrwA0H9PybrhDCgN402AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd0f47b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a sample to view the data\n",
    "plt.imshow(mnist.train.images[5].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Generator\n",
    "\n",
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        \n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Discriminator\n",
    "\n",
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        \n",
    "        alpha=0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "        \n",
    "        return output, logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder\n",
    "\n",
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D_output_real, D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)*(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
      "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adjusted to my computer \n",
    "batch_size = 1 # try 100\n",
    "epochs = 5 # try 500\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a sample per epoch\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 1 of 5 total...\n",
      "Currently on Epoch 2 of 5 total...\n",
      "Currently on Epoch 3 of 5 total...\n",
      "Currently on Epoch 4 of 5 total...\n",
      "Currently on Epoch 5 of 5 total...\n"
     ]
    }
   ],
   "source": [
    "# Run Session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # // indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "        saver.save(sess, './models/500_epoch_model.ckpt.RH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/500_epoch_model.ckpt.RH\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/500_epoch_model.ckpt.RH')\n",
    "    \n",
    "    for x in range(5):\n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xfb03cc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBQhB8IivADQf0H6ERr3hzp28EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf0c4e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(samples[0].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looks like a 6!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
